

Main memory and the registers built into each processing core are the only general-purpose storage that the cpu can access directly.

If the
data are not in memory, they must be moved there before the CPU can operate on them.


Registers that are built into each CPU core are generally accessible within one cycle of the CPU clock.


Completing a memory access may take many cycles of the CPU clock. In such cases, the processor normally needs to stall, since it does not have the data required to complete the instruction that it
is executing. 

The remedy is to add fast memory between the CPU and main memory, typically on the CPU chip for fast access. Such a cache.


Not only are we concerned with the relative speed of accessing physical memory, but we also must ensure correct operation. For proper system operation, we must protect the operating system from access by user processes, as well as protect user processes from one another. This protection must be provided by the hardware, because the operating system doesn’t usually intervene between the CPU and its memory accesses.

____

We first need to make sure that each process has a separate memory space. Separate per-process memory space protects the processes from each other and is fundamental to having multiple processes loaded in memory for concurrent execution.


To separate memory spaces, we need the ability to determine the
range of legal addresses that the process may access and to ensure that the process can access only these legal addresses.

We can provide this protection by using two registers, usually a base and a limit. The base register holds the smallest legal physical memory address; the limit register specifies the size of the range for logical address. 

For example, if the base register holds 300040 and the limit register is 120900, then the program can legally access all addresses from 300040 through 420939 (inclusive).

>  Figure 9.1.   base and limit


> (Figure 9.2).  Protection with base limit


Protection of memory space is accomplished by having the CPU hardware compare every address generated in user mode with the registers. Any attempt by a program executing in user mode to access operating-system memory or other users’ memory results in a trap to the operating system, which treats the attempt as a fatal error.


The operating system, executing in kernel mode, is given unrestricted
access to both operating-system memory and users’ memory.


#### Memory Protection

Each logical address must fall within the range specified by the limit register. The MMU maps the logical address dynamically by adding the value in the relocation register. This mapped address is sent to memory.

When the CPU scheduler selects a process for execution, the dispatcher loads the relocation and limit registers with the correct values as part of the context switch. Because every address generated by a CPU is checked against these registers, we can protect both the operating system and the other users’ programs and data from being modified by this running process.

> 9.6 Hardware Support for relocation and limit registers




___

#### Address Binding

program resides on a disk as a binary executable file. To run, the
program must be brought into memory and placed within the context of a process where it becomes eligible for execution on an available CPU.

Eventually, the process terminates, and its memory is reclaimed
for use by other processes.

Compile time. If you know at compile time where the process will reside in memory, then absolute code can be generated.

Load time. If it is not known at compile time where the process will reside in memory, then the compiler must generate relocatable code. In this case, final binding is delayed until load time.


Execution time. If the process can be moved during its execution from one memory segment to another, then binding must be delayed until run time. Special hardware must be available for this scheme to work. Most operating systems use this method.


#### Logical Vs Physical Memory

An address generated by the CPU is commonly referred to as a logical address, whereas an address seen by the memory unit—that is, the one loaded into the memory-address register of the memory—is commonly referred to as a physical address.


The set of all logical addresses generated
by a program is a logical address space. The set of all physical addresses
corresponding to these logical addresses is a physical address space.

The run-time mapping from virtual to physical addresses is done by a
hardware device called the memory-management unit (MMU)

> MMU 9.4

The base register is now called
a relocation register. The value in the relocation register is added to every
address generated by a user process at the time the address is sent to memory

___

##### Dynamic Loading

it has been necessary for the entire program and all
data of a process to be in physical memory for the process to execute. The size
of a process has thus been limited to the size of physical memory. To obtain
better memory-space utilization, we can use dynamic loading. With dynamic
loading, a routine is not loaded until it is called. All routines are kept on disk
in a relocatable load format. The main program is loaded into memory and
is executed. When a routine needs to call another routine, the calling routine
first checks to see whether the other routine has been loaded. If it has not, the
relocatable linking loader is called to load the desired routine into memory and
to update the program’s address tables to reflect this change. Then control is
passed to the newly loaded routine.

____
### 9.2 Contiguous Memory Allocation


The memory is usually divided into two partitions: one for the operating system and one for the user processes.

In contiguous mem-
ory allocation, each process is contained in a single section of memory that
is contiguous to the section containing the next process.


One of the simplest methods of allocating memory is to assign processes to variably sized partitions in memory, where each partition may contain exactly one process. 

In this variable-partition scheme, the operating system keeps a table indicating which parts of memory are available and which are occupied. 

Initially, all memory is available for user processes and is considered one large block of available memory, a hole. Eventually, memory contains a set of holes of various sizes.

> 9.7 Variable Partition


the memory blocks available comprise a set of
holes of various sizes scattered throughout memory. When a process arrives
and needs memory, the system searches the set for a hole that is large enough
for this process. If the hole is too large, it is split into two parts. One part is
allocated to the arriving process; the other is returned to the set of holes.


This procedure is a particular instance of the general dynamic storage-
allocation problem, which concerns how to satisfy a request of size n from a
list of free holes. There are many solutions to this problem. The first-fit, best-fi ,
and worst-fi strategies are the ones most commonly used to select a free hole
from the set of available holes.

First fit. Allocate the first hole that is big enough. Searching can start either
at the beginning of the set of holes or at the location where the previous
first-fit search ended. We can stop searching as soon as we find a free hole
that is large enough.
• Best fi . Allocate the smallest hole that is big enough. We must search the
entire list, unless the list is ordered by size. This strategy produces the
smallest leftover hole.
• Worst fit. Allocate the largest hole. Again, we must search the entire list,
unless it is sorted by size. This strategy produces the largest leftover hole,
which may be more useful than the smaller leftover hole from a best-fit
approach.


___

#### Fragmentation

Both the first-fit and best-fit strategies for memory allocation suffer from exter-nal fragmentation.

the free memory space is broken into little pieces. External fragmentation exists when there is enough total memory space to satisfy a request but the available spaces are not contiguous: storage is fragmented into a large number of small holes.


The general approach to avoiding this problem is to break the physical memory into fixed-sized blocks and allocate memory in units based on block size. With this approach, the memory allocated to a process may be slightly larger than the requested memory. The difference between these two numbers is internal fragmentation —unused memory that is internal to a partition.

One solution to the problem of external fragmentation is compaction. The goal is to shuffle the memory contents so as to place all free memory together in one large block.


___

#### 9.3 Paging

Another possible solution to the external-fragmentation problem is to permit the logical address space of processes to be noncontiguous, thus allowing a process to be allocated physical memory wherever such memory is available. This is the strategy used in paging, the most common memory-management
technique for computer systems.

paging, a memory-management scheme that permits a process’s physical address space to be non-contiguous. Paging avoids external fragmentation and the associated need for compaction, two problems that plague contiguous memory allocation. Because it offers numerous advantages, paging in its various forms is used in most operating systems, from those for large servers through those for mobile devices.
Paging is implemented through cooperation between the operating system and the computer hardware.

____

#### Basic Method of Paging

The basic method for implementing paging involves breaking physical memory into fixed-sized blocks called frames and breaking logical memory into blocks of the same size called pages. 

When a process is to be executed, its pages are loaded into any available memory frames from their source (a file system or the backing store). 

The backing store is divided into fixed-sized blocks that are the same size as the memory frames or clusters of multiple frames.


Every address generated by the CPU is divided into two parts: a page number (p) and a page offset (d):

The page number is used as an index into a per-process page table.

The page table contains the base address of each frame
in physical memory, and the offset is the location in the frame being referenced.

Thus, the base address of the frame is combined with the page offset to define the physical memory address.

> Figure 9.8 Paging Hardware

> Figure 9.9 Paging Model of logical and Physical memory


___

The page size (like the frame size) is defined by the hardware. The size of a page is a power of 2, typically varying between 4 KB and 1 GB per page, depending on the computer architecture


When we use a paging scheme, we have no external fragmentation: any free frame can be allocated to a process that needs it. However, we may have some internal fragmentation.

Today, pages are typically either 4 KB or 8 KB in size, and some systems support even larger page sizes.

`getconf PAGESIZE` for Unix `4096` which is 4kb

The first page of the process is loaded into one of the allocated frames, and the frame number is put in the page table for this process. The next page is loaded into another frame, its frame number is put into the page table, and so on



The programmer
views memory as one single space, containing only this one program. In fact,
the user program is scattered throughout physical memory, which also holds other programs.

user process by definition is unable to access memory it does
not own. It has no way of addressing memory outside of its page table, and the
table includes only those pages that the process owns.



allocation details of physical memory—which frames are allocated,
which frames are available, how many total frames there are, and so on. This information is generally kept in a single, system-wide data structure called a frame table. The frame table has one entry for each physical page frame, indicating whether the latter is free or allocated and, if it is allocated, to which page of which process (or processes).



The operating system maintains a copy of the page table for each process, just as it maintains a copy of the instruction counter and register contents. This copy is used to translate logical addresses to physical addresses whenever the operating system must map a logical address to a physical address manually.


_____


### Hardware Support

##### Translation Look-Aside Buffer


to access location i. We must first index into the page table, using the value to offset by the page number for i and combining with frame number. 
Then producing the actual address and accessing the desired place in memory.
This is two memory accesses for accessing the data.

The standard solution to this problem is to use a special, small, fast-lookup hardware cache called a translation look-aside buffer (TLB). The TLB is associative, high-speed memory. Each entry in the TLB consists of two parts: a key (or tag) and a value. When the associative memory is presented with an item, the item is compared with all keys simultaneously. If the item is found, the corresponding value field is returned. 

The search is fast; a TLB lookup in modern hardware is part of the instruction pipeline, essentially adding no performance penalty.


The TLB contains only a few of the page-table entries. When a logical address is generated by the CPU, the MMU first checks if its page number is present in the TLB. If the page number is found, its frame number is immediately available and is used to access memory.

If the page number is not in the TLB (known as a TLB miss), address
translation proceeds.


where a memory reference to the page table must be made. When the frame number is obtained to access memory. In addition, we add the page number and frame number to the TLB, so that they will be found quickly on the next reference.

> (Figure 9.12) Paging hardware with TLB

some TLBs allow certain entries to be wired down, meaning that
they cannot be removed from the TLB. Typically, TLB entries for key kernel code are wired down.

____


The percentage of times that the page number of interest is found in the TLB is called the hit ratio. An 80-percent hit ratio, for example, means that we find the desired page number in the TLB 80 percent of the time.

___

#### Paging Memory Protection

Memory protection in a paged environment is accomplished by protection bits
associated with each frame. Normally, these bits are kept in the page table.


One additional bit is generally attached to each entry in the page table: a
valid –invalid bit. When this bit is set to valid, the associated page is in the
process’s logical address space and is thus a legal (or valid) page. When the
bit is set to invalid, the page is not in the process’s logical address space. Illegal
addresses are trapped by use of the valid –invalid bit. The operating system
sets this bit for each page to allow or disallow access to the page.


valid –invalid bit is set to invalid, and the computer will trap to the operating
system (invalid page reference).

___


#### 9.5 Swapping

Process instructions and the data they operate on must be in memory to be executed. However, a process, or a portion of a process, can be swapped
temporarily out of memory to a backing store and then brought back into memory for continued execution (Figure 9.19). Swapping makes it possible for the total physical address space of all processes to exceed the real physical memory of the system, thus increasing the degree of multiprogramming in a
system.




Most systems, including Linux and Windows, now use a variation of swap-
ping in which pages of a process—rather than an entire process—can be
swapped. This strategy still allows physical memory to be oversubscribed, but
does not incur the cost of swapping entire processes, as presumably only a
small number of pages will be involved in swapping